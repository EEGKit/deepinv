{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepinv.physics.generator import DiffractionBlurGenerator\n",
    "from src.utils.display_utils import show_images\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transform\n",
    "from product_convolution import image_to_patches, patches_to_image, product_convolution2d_patches, get_psf_product_convolution2d_patches, unity_partition_function_2d, crop_unity_partition_2d, compute_patch_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 546\n",
    "image = torch.randn(1,3,image_size,image_size)\n",
    "patch_size = 128\n",
    "overlap = 64\n",
    "\n",
    "patches = image_to_patches(image, patch_size=patch_size, overlap=overlap)\n",
    "image_r = patches_to_image(patches, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patches.shape)\n",
    "print(image_r.shape)\n",
    "print(compute_patch_info(image.shape[-2:], patch_size, overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import gridspec\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\\..*\")\n",
    "\n",
    "_TensorArray = Union[Tensor, np.ndarray]\n",
    "\n",
    "def to_numpy_image(input):\n",
    "    if isinstance(input, Tensor):\n",
    "        if input.dim() == 3:\n",
    "            return input.detach().cpu().permute(1, 2, 0).numpy()\n",
    "        elif input.dim() == 4:\n",
    "            return input.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        print(\"Warning: input is already a numpy array\")\n",
    "        return input\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot convert {type(input)} to numpy image\")\n",
    "def show_images(\n",
    "    imgs: Union[_TensorArray, List[_TensorArray], Tuple[_TensorArray]],\n",
    "    title: List[str] = None,\n",
    "    suptitle: str = None,\n",
    "    ncols: int = None,\n",
    "    colorbar: Optional[bool] = False,\n",
    "    cmap: str = None,\n",
    "    vmin: Optional[float] = None,\n",
    "    vmax: Optional[float] = None,\n",
    "    savename: Optional[str] = None,\n",
    "    figsize: Optional[int] = 3,\n",
    "    interpolation: Optional[str] = None,\n",
    "):\n",
    "\n",
    "    if isinstance(imgs, List) or isinstance(imgs, Tuple):\n",
    "        if isinstance(imgs[0], np.ndarray):\n",
    "            imgs = np.concatenate(imgs, axis=0)\n",
    "        elif isinstance(imgs[0], torch.Tensor):\n",
    "            imgs = to_numpy_image(torch.cat(imgs, dim=0))\n",
    "    else:\n",
    "        imgs = to_numpy_image(imgs)\n",
    "\n",
    "    if imgs.ndim == 3:\n",
    "        H, W, C = imgs.shape\n",
    "        B = 1\n",
    "    elif imgs.ndim == 4:\n",
    "        B, H, W, C = imgs.shape\n",
    "\n",
    "    if (ncols is not None) and (B % ncols == 0):\n",
    "        nrows = B // ncols\n",
    "    else:\n",
    "        nrows = 1\n",
    "        ncols = B\n",
    "    offset = 0 if not colorbar else 0.75\n",
    "    fig = plt.figure(figsize=(ncols * (figsize + offset), nrows * figsize))\n",
    "    gs = gridspec.GridSpec(ncols=ncols, nrows=nrows)\n",
    "    gs.update(wspace=0.025, hspace=0.025)\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = \"gray\" if C == 1 else None\n",
    "    i = 0\n",
    "\n",
    "    if title is None:\n",
    "        title = [\"\"]\n",
    "    if len(title) != B:\n",
    "        title += [\"\"] * (B - len(title))\n",
    "    with warnings.catch_warnings():\n",
    "        if nrows > 1 and ncols > 1:\n",
    "            for r in range(nrows):\n",
    "                for c in range(ncols):\n",
    "                    axs = plt.subplot(gs[r, c])\n",
    "                    im = axs.imshow(\n",
    "                        imgs[i],\n",
    "                        vmin=vmin,\n",
    "                        vmax=vmax,\n",
    "                        cmap=cmap,\n",
    "                        interpolation=interpolation,\n",
    "                    )\n",
    "                    axs.set_xticks([])\n",
    "                    axs.set_yticks([])\n",
    "                    if colorbar:\n",
    "                        divider = make_axes_locatable(axs)\n",
    "                        cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "                        plt.colorbar(im, cax=cax)\n",
    "                    if title:\n",
    "                        axs.set_title(title[i], pad=3)\n",
    "\n",
    "                    i += 1\n",
    "        elif nrows > 1 or ncols > 1:\n",
    "            for c in range(max(ncols, nrows)):\n",
    "                axs = plt.subplot(gs[c])\n",
    "                im = axs.imshow(\n",
    "                    imgs[c], vmin=vmin, vmax=vmax, cmap=cmap, interpolation=interpolation\n",
    "                )\n",
    "                axs.set_xticks([])\n",
    "                axs.set_yticks([])\n",
    "                if colorbar:\n",
    "                    divider = make_axes_locatable(axs)\n",
    "                    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "                    plt.colorbar(im, cax=cax)\n",
    "                if title:\n",
    "                    axs.set_title(title[c], pad=3)\n",
    "\n",
    "        else:\n",
    "            axs = plt.subplot(gs[0])\n",
    "            im = axs.imshow(\n",
    "                imgs.squeeze(), vmin=vmin, vmax=vmax, cmap=cmap, interpolation=interpolation\n",
    "            )\n",
    "            axs.set_xticks([])\n",
    "            axs.set_yticks([])\n",
    "            if colorbar:\n",
    "                divider = make_axes_locatable(axs)\n",
    "                cax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "                plt.colorbar(im, cax=cax)\n",
    "            if title:\n",
    "                axs.set_title(title[0], pad=3)\n",
    "\n",
    "        if suptitle is not None:\n",
    "            fig.suptitle(suptitle, y=1.03)\n",
    "        if savename is not None:\n",
    "            fig.savefig(savename, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% TEST PRODUCT-CONVOLUTION\n",
    "path_1 = '/home/minhhai/Works/datasets/FFHQ/images1024x1024/00003.png'\n",
    "path_2 = '/home/minhhai/Works/datasets/FFHQ/images1024x1024/00014.png'\n",
    "\n",
    "image_1 = Image.open(path_1)\n",
    "image_1 = transform.ToTensor()(image_1)\n",
    "\n",
    "image_2 = Image.open(path_2)\n",
    "image_2 = transform.ToTensor()(image_2)\n",
    "\n",
    "image = torch.stack([image_1, image_2], dim=0).cuda()\n",
    "show_images(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_size = (31, 31)\n",
    "patch_size = (128, 128)\n",
    "overlap = (64, 64)\n",
    "image_size = (512,512)\n",
    "image = torch.zeros((1,3) + image_size).cuda()\n",
    "image[...,30,30] = 1.\n",
    "patches = image_to_patches(image, patch_size, overlap)\n",
    "patch_info = compute_patch_info(image_size, patch_size, overlap)\n",
    "K = patches.size(2) * patches.size(3)\n",
    "\n",
    "\n",
    "generator = DiffractionBlurGenerator(\n",
    "    psf_size, num_channels=3, fc=0.2, device='cuda')\n",
    "h = torch.stack([generator.step(image.size(0))['filter']\n",
    "                 for _ in range(K)], dim=2)\n",
    "masks = unity_partition_function_2d(image.shape[-2:], patch_size, overlap)\n",
    "w, _ = crop_unity_partition_2d(masks, patch_size, overlap, psf_size)\n",
    "w = w.unsqueeze(0).unsqueeze(1).flatten(2,3).cuda()\n",
    "\n",
    "show_images(h.transpose(2,1).flatten(0, 1) ** 0.25, ncols=K)\n",
    "blurry = product_convolution2d_patches(image, w, h, patch_size, overlap)\n",
    "show_images(blurry ** 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (45, 68)\n",
    "psf_size = (31, 31)\n",
    "patch_size = (128, 128)\n",
    "overlap = (64, 64)\n",
    "image_size = 256\n",
    "\n",
    "image = torch.zeros(2, 3, image_size, image_size, device='cuda')\n",
    "image[..., position[0]: position[0] + 1, position[1]: position[1] + 1] = 1.\n",
    "show_images(image)\n",
    "info = compute_patch_info(image_size, patch_size, overlap)\n",
    "K = np.prod(info['num_patches'])\n",
    "masks = unity_partition_function_2d(image.shape[-2:], patch_size, overlap)\n",
    "w, _ = crop_unity_partition_2d(masks, patch_size, overlap, psf_size)\n",
    "w = w.unsqueeze(0).unsqueeze(1).flatten(2,3).cuda()\n",
    "# w = torch.ones_like(w)\n",
    "h = torch.stack([generator.step(image.size(0))['filter']\n",
    "                 for _ in range(K)], dim=2)\n",
    "blurry = product_convolution2d_patches(image, w, h, patch_size, overlap)\n",
    "\n",
    "psf_pc = blurry[..., position[0] - psf_size[0] // 2: position[0] + psf_size[0] //\n",
    "            2 + 1, position[1] - psf_size[1] // 2: position[1] + psf_size[1] // 2 + 1]\n",
    "\n",
    "patches = image_to_patches(image, patch_size, overlap)\n",
    "psf = get_psf_product_convolution2d_patches(\n",
    "    h, w, position, overlap, patches.shape[2:4])\n",
    "\n",
    "diff = psf_pc[:,0:1,...] - psf[:,0:1,...]\n",
    "show_images(torch.cat((psf_pc[:,0:1,...], psf[:,0:1,...], diff), dim = 0) ** 0.25, colorbar=True, suptitle=f'Norm Diff: {torch.norm(diff).item():.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = (45, 0)\n",
    "psf_size = (31, 31)\n",
    "patch_size = (128, 128)\n",
    "overlap = (64, 64)\n",
    "\n",
    "image = torch.zeros(2, 3, 256, 256, device='cuda')\n",
    "image[..., position[0]: position[0] + 1, position[1]: position[1] + 1] = 1.\n",
    "show_images(image)\n",
    "\n",
    "masks = unity_partition_function_2d(image.shape[-2:], patch_size, overlap)\n",
    "w, _ = crop_unity_partition_2d(masks, patch_size, overlap, psf_size)\n",
    "w = w.unsqueeze(0).unsqueeze(1).flatten(2,3).cuda()\n",
    "# w = torch.ones_like(w)\n",
    "h = torch.stack([generator.step(image.size(0))['filter']\n",
    "                 for _ in range(K)], dim=2)\n",
    "blurry = product_convolution2d_patches(image, w, h, patch_size, overlap)\n",
    "\n",
    "psf_pc = blurry[..., :psf_size[0],: psf_size[1]]\n",
    "\n",
    "patches = image_to_patches(image, patch_size, overlap)\n",
    "psf = get_psf_product_convolution2d_patches(\n",
    "    h, w, position, overlap, patches.shape[2:4])\n",
    "\n",
    "diff = psf_pc[:,0:1,...] - psf[:,0:1,...]\n",
    "show_images(torch.cat((psf_pc[:,0:1,...], psf[:,0:1,...], diff), dim = 0) ** 0.25, colorbar=True, suptitle=f'Norm Diff: {torch.norm(diff).item():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_size = (31, 31)\n",
    "patch_size = (128, 128)\n",
    "overlap = (64, 64)\n",
    "image = torch.zeros(2, 3, 256, 256, device='cuda')\n",
    "\n",
    "masks = unity_partition_function_2d(image.shape[-2:], patch_size, overlap)\n",
    "w, _ = crop_unity_partition_2d(masks, patch_size, overlap, psf_size)\n",
    "w = w.unsqueeze(0).unsqueeze(1).flatten(2,3).cuda()\n",
    "# w = torch.ones_like(w)\n",
    "h = torch.stack([generator.step(image.size(0))['filter']\n",
    "                 for _ in range(K)], dim=2)\n",
    "\n",
    "for i in range(psf_size[0] // 2, 256 - psf_size[0] // 2):\n",
    "    for j in range(psf_size[1] // 2, 256 - psf_size[1] // 2):\n",
    "        position = (i, j)\n",
    "        image = torch.zeros(2, 3, 256, 256, device='cuda')\n",
    "        image[..., position[0]: position[0] + 1, position[1]: position[1] + 1] = 1.\n",
    "        blurry = product_convolution2d_patches(image, w, h, patch_size, overlap)\n",
    "\n",
    "        psf_pc = blurry[..., position[0] - psf_size[0] // 2: position[0] + psf_size[0] //\n",
    "                    2 + 1, position[1] - psf_size[1] // 2: position[1] + psf_size[1] // 2 + 1]\n",
    "        patches = image_to_patches(image, patch_size, overlap)\n",
    "        psf = get_psf_product_convolution2d_patches(\n",
    "            h, w, position, overlap, patches.shape[2:4])\n",
    "\n",
    "        diff = psf_pc[:,0:1,...] - psf[:,0:1,...]\n",
    "        if torch.norm(diff) > 1e-5:\n",
    "            print(f'{i, j}: ', torch.norm(diff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
