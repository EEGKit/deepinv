{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Remote sensing with satellite images\n\nIn this example we demonstrate remote sensing inverse problems for multispectral satellite imaging.\nWe will focus on pan-sharpening, i.e., recovering high-resolution multispectral images from measurement pairs of\nlow-resolution multispectral images and high-resolution panchromatic (single-band) images with the forward\noperator :class:`deepinv.physics.Pansharpen`.\n\nThese have important applications for image restoration in environmental monitoring, urban planning, disaster recovery etc.\n\nWe provide a convenient satellite image dataset for pan-sharpening :class:`deepinv.datasets.NBUDataset` provided in the paper [A Large-Scale Benchmark Data Set for Evaluating Pansharpening Performance](https://ieeexplore.ieee.org/document/9082183)\nwhich includes data from several satellites such as WorldView satellites.\n\nFor remote sensing experiments, DeepInverse provides the following:\n\n.. seealso::\n\n    - :class:`Hyperspectral unmixing <deepinv.physics.HyperSpectralUnmixing>`\n    - :class:`Super resolution <deepinv.physics.Downsampling>`\n    - :class:`Satellite imagery dataset <deepinv.datasets.NBUDataset>`\n    - Metrics for multispectral data: :class:`QNR <deepinv.loss.metric.QNR>`, :class:`SpectralAngleMapper <deepinv.loss.metric.SpectralAngleMapper>`, :class:`ERGAS <deepinv.loss.metric.ERGAS>`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import deepinv as dinv\nimport torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load raw pan-sharpening measurements\nThe dataset includes raw pansharpening measurements\ncontaining ``(MS, PAN)`` where ``MS`` are the low-res (4-band) multispectral and ``PAN`` are the high-res\npanchromatic images. Note there are no ground truth images!\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The pan-sharpening measurements are provided as a :class:`deepinv.utils.TensorList`, since\n  the pan-sharpening physics :class:`deepinv.physics.Pansharpen` is a stacked physics combining\n  :class:`deepinv.physics.Downsampling` and :class:`deepinv.physics.Decolorize`.\n  See the User Guide `physics_combining` for more information.</p></div>\n\nNote, for plotting purposes we only plot the first 3 bands (RGB).\n\nNote also that the linear adjoint must assume the unknown spectral response function (SRF).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DATA_DIR = dinv.utils.get_data_home()\ndataset = dinv.datasets.NBUDataset(DATA_DIR, return_pan=True, download=True)\n\ny = dataset[0].unsqueeze(0)  # MS (1,4,256,256), PAN (1,1,1024,1024)\n\nphysics = dinv.physics.Pansharpen((4, 1024, 1024), factor=4)\n\n# Pansharpen with classical Brovey method\nx_hat = physics.A_dagger(y)  # shape (1,4,1024,1024)\n\ndinv.utils.plot(\n    [\n        y[0][:, :3],\n        y[1],  # Note this will be interpolated to match high-res image size\n        x_hat[:, :3],\n        physics.A_adjoint(y)[:, :3],\n    ],\n    titles=[\n        \"Input MS\",\n        \"Input PAN\",\n        \"Pseudo-inverse using Brovey method\",\n        \"Linear adjoint\",\n    ],\n    dpi=1200,\n)\n\n# Evaluate performance - note we can only use QNR as we have no GT\nqnr = dinv.metric.QNR()\nprint(qnr(x_net=x_hat, x=None, y=y, physics=physics))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate pan-sharpening measurements\nWe can also simulate pan-sharpening measurements so that we have pairs of\nmeasurements and ground truth. Now, the dataset loads ground truth images ``x``.\nFor the pansharpening physics, we assume a flat spectral response function,\nbut this can also be jointly learned. We simulate Gaussian noise on the panchromatic images.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = dinv.datasets.NBUDataset(DATA_DIR, return_pan=False)\n\nx = dataset[0].unsqueeze(0)  # just MS of shape 1,4,256,256\n\nphysics = dinv.physics.Pansharpen((4, 256, 256), factor=4, srf=\"flat\")\n\ny = physics(x)\n\n# Pansharpen with classical Brovey method\nx_hat = physics.A_dagger(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving pan-sharpening with neural networks\nThe pan-sharpening physics is compatible with the rest of the DeepInverse library\nso we can solve the inverse problem using any method provided in the library.\nFor example, we use here the [PanNet](https://ieeexplore.ieee.org/document/8237455/) model.\n\nThis model can be trained using losses such as supervised learning using :class:`deepinv.loss.SupLoss`\nor self-supervised learning using Equivariant Imaging :class:`deepinv.loss.EILoss`, which was applied to\npan-sharpening in [Wang et al., Perspective-Equivariant Imaging: an Unsupervised Framework for Multispectral Pansharpening](https://arxiv.org/abs/2403.09327)\n\nFor evaluation, we use the standard full-reference metrics (ERGAS, SAM) and no-reference (QNR).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This is a tiny example using 5 images. We demonstrate training for 1 epoch for speed, but you can train from scratch using 50 epochs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = dinv.models.PanNet(hrms_shape=(4, 256, 256))\nx_net = model(y, physics)\n\n# Example training loss using measurement consistency on the multispectral images\n# and Stein's Unbiased Risk Estimate on the panchromatic images.\nloss = dinv.loss.StackedPhysicsLoss(\n    [dinv.loss.MCLoss(), dinv.loss.SureGaussianLoss(0.05)]\n)\n\n# Evaluate performance when ground-truth available\nsam = dinv.metric.distortion.SpectralAngleMapper()\nergas = dinv.metric.distortion.ERGAS(factor=4)\nqnr = dinv.metric.QNR()\nprint(sam(x_hat, x), ergas(x_hat, x), qnr(x_hat, x=None, y=y, physics=physics))\n\n# Load optimizer and pretrained model\noptimizer = torch.optim.Adam(model.parameters())\n\nfrom deepinv.models.utils import get_weights_url\n\nfile_name = \"demo_nbu_pansharpen.pth\"\nurl = get_weights_url(model_name=\"demo\", file_name=file_name)\nckpt = torch.hub.load_state_dict_from_url(\n    url, map_location=lambda storage, loc: storage, file_name=file_name\n)\nmodel.load_state_dict(ckpt[\"state_dict\"])\noptimizer.load_state_dict(ckpt[\"optimizer\"])\n\n# Train using deepinv Trainer\nfrom torch.utils.data import DataLoader\n\ntrainer = dinv.Trainer(\n    model=model,\n    physics=physics,\n    optimizer=optimizer,\n    losses=loss,\n    metrics=[sam, ergas],\n    train_dataloader=DataLoader(dataset),\n    epochs=1,\n    online_measurements=True,\n    plot_images=False,\n    compare_no_learning=True,\n    no_learning_method=\"A_dagger\",\n    show_progress_bar=False,\n)\n\ntrainer.train()\ntrainer.test(DataLoader(dataset))\n\n# Plot results\ndinv.utils.plot(\n    [\n        x[:, :3],\n        y[0][:, :3],\n        y[1],\n        x_hat[:, :3],\n        x_net[:, :3],\n    ],\n    titles=[\"x HRMS\", \"y LRMS\", \"y PAN\", \"Estimate (classical)\", \"Estimate (PanNet)\"],\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}